{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8151e518",
   "metadata": {},
   "source": [
    "### EXTRACCIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc73efca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "from tqdm.auto import tqdm\n",
    "import pickle as pkl\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "\n",
    "from libraries.serpapi import serpapi\n",
    "from libraries.preprocess import preprocess\n",
    "from libraries.preprocess import pipeline\n",
    "from libraries.preprocess import airtable\n",
    "from machine_learning_model.src.textprocessing.preprocess import normalize_text, remove_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e2498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los puestos y nuestra API_KEY\n",
    "today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "api_key = str(input(\"Introduce tu API_KEY de SerpApi: \"))\n",
    "\n",
    "lista_puestos = pd.read_excel(\"data/lista_puestos.xlsx\", header = None)\n",
    "lista_puestos.columns = [\"jobs\"]\n",
    "lista_puestos = lista_puestos[\"jobs\"].tolist()\n",
    "\n",
    "with open(\"data/lista_puestos_ingles.txt\", \"r\") as file:\n",
    "    lista_puestos_ingles = file.read()\n",
    "    \n",
    "lista_puestos_ingles = lista_puestos_ingles.split(\"\\n\")\n",
    "\n",
    "lista_puestos_ingles = [x for x in [x.replace(\"Developer\", \"\") for x in lista_puestos_ingles] if len(x.split()) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880c6ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos España como país de búsqueda\n",
    "spain = [[\".es\", \"Spain\"]]\n",
    "\n",
    "# Ajustamos Latino-américa como países de búsqueda\n",
    "latam = [[\"com.ar\", \"Argentina\"]         ,\n",
    "         [\"com.bo\", \"Bolivia\"]           ,\n",
    "         [\"com.br\", \"Brazil\"]            ,\n",
    "         [\"cl\", \"Chile\"]             ,\n",
    "         [\"com.co\", \"Colombia\"]          ,\n",
    "         [\"co.cr\", \"Costa Rica\"]        ,\n",
    "         [\"com.cu\", \"Cuba\"]              ,\n",
    "         [\"com.do\", \"Dominican Republic\"],\n",
    "         [\"com.ec\", \"Ecuador\"]           ,\n",
    "         [\"com.sv\", \"El Salvador\"]       ,\n",
    "         [\"com.gt\", \"Guatemala\"]         ,\n",
    "         [\"hn\", \"Honduras\"]          ,\n",
    "         [\"com.mx\", \"Mexico\"]            ,\n",
    "         [\"com.ni\", \"Nicaragua\"]         ,\n",
    "         [\"com.pa\", \"Panama\"]            ,\n",
    "         [\"com.py\", \"Paraguay\"]          ,\n",
    "         [\"com.pe\", \"Peru\"]              ,\n",
    "         [\"com.pr\", \"Puerto Rico\"]       ,\n",
    "         [\"com.uy\", \"Uruguay\"]]\n",
    "\n",
    "paises = str(input(\"¿Dónde quieres hacer búsquedas de empleo? Para España: spain, para Latinoamérica: latam \"))\n",
    "\n",
    "if paises == \"spain\":\n",
    "    paises = spain\n",
    "    puestos = lista_puestos\n",
    "    pais = \"spain\"\n",
    "\n",
    "elif paises == \"latam\":\n",
    "    paises = latam\n",
    "    puestos = lista_puestos_ingles\n",
    "    pais = \"latam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aabca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for abr, country in paises:\n",
    "    \n",
    "    for q in puestos: # Modificar lista de puestos según país/países de preferencia.\n",
    "\n",
    "        try:\n",
    "            \n",
    "            for pagination in range(100):\n",
    "                \n",
    "                print(f\"{q:60}{pagination}\")\n",
    "\n",
    "                q_params = {\"q\"             : q,\n",
    "                            \"api_key\"       : api_key,\n",
    "                            \"location\"      : country.title(),\n",
    "                            \"start\"         : pagination*10,\n",
    "                            \"chips\"         : \"date_posted:3days\" # Ofertas de empleo de hace 3 días hasta hoy\n",
    "                            }\n",
    "\n",
    "                response = serpapi.job_search(**q_params)\n",
    "\n",
    "\n",
    "                if (\"error\" in response) or (response.get(\"jobs_results\") == None) or (len(response.get(\"jobs_results\")) < 10):\n",
    "                    break\n",
    "\n",
    "                df_response = pd.json_normalize(response[\"jobs_results\"])\n",
    "\n",
    "                df_response.columns = [x.split(\".\")[0] if len(x.split(\".\")) == 1 else x.split(\".\")[-1] for x in df_response.columns]\n",
    "\n",
    "                df_response[\"country_search\"] = country.title()\n",
    "                \n",
    "                df = pd.concat(objs = [df, df_response], ignore_index = True)\n",
    "                \n",
    "        except:\n",
    "            \n",
    "            print(f\"Error {q} ***************************************************************\")\n",
    "                 \n",
    "df = df.drop_duplicates(subset = \"job_id\").reset_index(drop = True) # Eliminamos duplicados si existen en \"job_id\"\n",
    "df = df.drop_duplicates(subset = \"description\").reset_index(drop = True) # Eliminamos duplicados por descripción de oferta\n",
    "df[\"date_posted\"] = datetime.strptime(today, \"%Y-%m-%d\").date()\n",
    "\n",
    "df.to_csv(f\"data/extracted/extraction_{today}_{pais}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3f346e",
   "metadata": {},
   "source": [
    "### PROCESAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc90867",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df = pipeline.pipeline(funciones = pipeline.funciones, \n",
    "                       df = df)\n",
    "\n",
    "df = df.rename(columns = {\"experience_level\" : \"experience_levels\",\n",
    "                          \"job_specialization\" : \"Especialidad\",\n",
    "                          \"job_profile\" : \"Perfil\"})\n",
    "\n",
    "df.to_csv(f\"data/cleaned/{pais}_cleaned_data_{today}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53738705",
   "metadata": {},
   "source": [
    "### SUBIDA AIRTABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e7404",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "airtable_key = str(input(\"Introduce tu API_KEY de airtable: \"))\n",
    "base = str(input(\"Introduce la base de la tabla destino: \"))\n",
    "table = str(input(\"Introduce la tabla destino: \"))\n",
    "\n",
    "airtable.airtable_post_spain(df = df, \n",
    "                             airtable_key = airtable_key, \n",
    "                             base = base, \n",
    "                             table = table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd5ed9e",
   "metadata": {},
   "source": [
    "### EXTRACCIÓN DE SALARIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ceb54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"salary_min_form\", \"salary_max_form\", \"currency_form\", \"time_lapse_form\"]] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ab6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_salary(description, job_id, location):\n",
    "    response = requests.post('http://localhost:3000/predict',\n",
    "                             data = json.dumps({\"description\" : description,\n",
    "                                                \"jobid\" : job_id,\n",
    "                                                \"location\" : location\n",
    "                                               }),\n",
    "                             headers = {\"Content-Type\" : \"application/json\"})\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    \n",
    "    return {'max': 0, 'min': 0, 'error_status_code': response.status_code}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f6d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_info = list()\n",
    "total_tokens = 0\n",
    "accumulate_cost = 0\n",
    "progress_steps = math.ceil(df.shape[0]*0.15)\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        salary_output = extract_salary(description = row.description, job_id = row.job_id, location = row.country)\n",
    "        sent_tokens = salary_output[\"token_count_sent_chat_gpt\"]\n",
    "        total_tokens += sent_tokens\n",
    "\n",
    "        cost = float(salary_output[\"cost\"])\n",
    "        accumulate_cost += cost\n",
    "\n",
    "        orignal_description_tokens = len(row.description.split(\" \"))\n",
    "        reduce_description_len = len(salary_output[\"reduce_description\"].split(\" \"))\n",
    "        ratio_sent_original_description = reduce_description_len/orignal_description_tokens\n",
    "\n",
    "        salary_info.append((row.job_id, salary_output[\"reduce_description\"], salary_output[\"min\"], salary_output[\"max\"], salary_output[\"currency\"], salary_output[\"time_lapse\"], salary_output[\"source\"], sent_tokens, orignal_description_tokens, ratio_sent_original_description, cost))\n",
    "\n",
    "        if (index%progress_steps) == 0:\n",
    "            \n",
    "            print(f\"[output salary: {salary_output}]\")\n",
    "            print(\"[------- Full Description -------]\")\n",
    "            print(row.description)\n",
    "            print(\"[------- Reduce description -------]\")\n",
    "            print(salary_output[\"reduce_description\"])\n",
    "            print(f\"==== Tokens sent for this JD:{sent_tokens} - Total sent tokens: {total_tokens} - tokens in complete description:{orignal_description_tokens} = Ratio sent/original description so far:{ratio_sent_original_description} | Cost for this JD:{cost} - Total cost so far: {accumulate_cost} ====\")\n",
    "\n",
    "    except Exception as e:\n",
    "        \n",
    "        print(f\"error: {e}\")\n",
    "\n",
    "print(f\"estimated_cost: {accumulate_cost} per: {df.shape[0]} jobs description | Total sent tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4753ae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df = pd.DataFrame(salary_info,\n",
    "                         columns=[\n",
    "                                    \"job_id\",\n",
    "                                    \"reduce_description\",\n",
    "                                    \"salary_min_gpt\",\n",
    "                                    \"salary_max_gpt\",\n",
    "                                    \"currency_gpt\",\n",
    "                                    \"time_lapse_gpt\",\n",
    "                                    \"source\",\n",
    "                                    \"token_count_sent_chat_gpt\",\n",
    "                                    \"token_count_original_description\",\n",
    "                                    \"token_rate_sent_original_description\",\n",
    "                                    \"gpt_cost\"\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813c0a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_with_salary = pd.merge(df, salary_df, on = \"job_id\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de37c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_jobs_count = jobs_with_salary.shape[0]\n",
    "jobs_with_salary_count = jobs_with_salary[jobs_with_salary[f\"salary_min_gpt\"] > 0].shape[0]\n",
    "\n",
    "print(f\"Salary jobs count: {all_jobs_count} | {jobs_with_salary_count} - jobs with salary {round(jobs_with_salary_count/all_jobs_count, 3)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee3cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_with_salary = jobs_with_salary[[\"job_id\", \"country\", \"experience\", \"experience_levels\", \"description\", \"email\",\n",
    "                                     \"Especialidad\", \"Perfil\", \"remote_work\", \"tech_skills\", \"title\", \"company_name\",\n",
    "                                     \"location\", \"source\", \"date_posted\", \"contract_type\", \"salary_min_gpt\",\n",
    "                                     \"salary_max_gpt\", \"currency_gpt\", \"time_lapse_gpt\"]]\n",
    "\n",
    "jobs_with_salary = jobs_with_salary.rename(columns = {\"salary_min_gpt\" : \"salary_min\",\n",
    "                                                      \"salary_max_gpt\" : \"salary_max\",\n",
    "                                                      \"currency_gpt\" : \"currency\",\n",
    "                                                      \"time_lapse_gpt\" : \"time_lapse\"})\n",
    "\n",
    "jobs_with_salary[\"currency\"].replace(\" \", np.nan, inplace = True)\n",
    "jobs_with_salary[\"time_lapse\"].replace(\" \", np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe58e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_with_salary.to_csv(f\"data/with_salaries/{pais}_cleaned_data_{today}_with_salaries.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
