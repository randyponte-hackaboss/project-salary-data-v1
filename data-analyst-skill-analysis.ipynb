{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Library Support","metadata":{}},{"cell_type":"code","source":"import os\nimport datetime\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom google.cloud import bigquery\nimport nltk\nfrom nltk.tokenize import word_tokenize, MWETokenizer\n\n# got tired of warnings üôÉ\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Only need to run once\n# nltk.download('punkt')","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:11:05.242854Z","iopub.execute_input":"2022-11-13T22:11:05.244062Z","iopub.status.idle":"2022-11-13T22:11:07.21475Z","shell.execute_reply.started":"2022-11-13T22:11:05.243912Z","shell.execute_reply":"2022-11-13T22:11:07.21277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Data from CSV","metadata":{}},{"cell_type":"code","source":"data_url = '../input/data-analyst-job-postings-google-search/gsearch_jobs.csv'\njobs_all = pd.read_csv(data_url).replace(\"'\",\"\", regex=True)\njobs_all.date_time = pd.to_datetime(jobs_all.date_time) # convert to date time\njobs_all = jobs_all.drop(labels=['Unnamed: 0', 'index'], axis=1, errors='ignore')\njobs_all.description_tokens = jobs_all.description_tokens.str.strip(\"[]\").str.split(\",\")","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:11:07.217469Z","iopub.execute_input":"2022-11-13T22:11:07.219982Z","iopub.status.idle":"2022-11-13T22:11:07.51743Z","shell.execute_reply.started":"2022-11-13T22:11:07.219934Z","shell.execute_reply":"2022-11-13T22:11:07.515763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Integrity Check","metadata":{}},{"cell_type":"code","source":"print(\"Big Query Statistics:\")\nprint(\"---------------------\")\nprint(f\"üö£‚Äç‚ôÄÔ∏è Rows of data: {len(jobs_all)}\")\n\nrepeat_jobs = jobs_all.job_id.value_counts()\ntry:\n    repeat_jobs = repeat_jobs[repeat_jobs>1].index[0]\n    repeat_jobs = len(repeat_jobs)\nexcept IndexError:\n    repeat_jobs = \"None\"\nprint(f\"üëØ‚Äç‚ôÄÔ∏è Number jobs repeated: {repeat_jobs}\")\n\nfirst_date = jobs_all.date_time.dt.date.min()\ntoday_date = datetime.date.today() #+ datetime.timedelta(days=2) # test function works\ndate_count = pd.DataFrame(jobs_all.date_time.dt.date.value_counts())\nmissing_dates = list(pd.date_range(start=first_date, end=today_date).difference(date_count.index))\nif len(missing_dates) > 0:\n    print(\"‚ùå Missing data for following dates:\")\n    for date in missing_dates:\n        print(date)\nelse:\n    print(f\"‚úÖ No missing dates of data since inception of: {first_date}\")\n\ndelta_days = (today_date - (first_date - datetime.timedelta(days=2))).days # first day was actually day prior but UTC\njobs_day = round(len(jobs_all)/delta_days)\nprint(f\"üßë‚Äçüíª Average number of jobs per day: {jobs_day}\")\nprint(f\"üìÜ Collecting data for {delta_days} days now...\")","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:11:07.519378Z","iopub.execute_input":"2022-11-13T22:11:07.520024Z","iopub.status.idle":"2022-11-13T22:11:07.58539Z","shell.execute_reply.started":"2022-11-13T22:11:07.519981Z","shell.execute_reply":"2022-11-13T22:11:07.582016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"def eda_plot(column, topn=10):\n    plt.figure(figsize=(4, 2))\n    jobs_all[column].value_counts().nlargest(topn).plot(kind='bar')\n    plt.title(f\"'{column}' column value counts\")\n    plt.ylabel(\"Counts\")\n    plt.xticks(rotation = 45, ha='right')\n    plt.show()\n\ncolumns = ['title', 'company_name', 'location', 'via', 'schedule_type', 'work_from_home']\n\nfor column in columns:\n    eda_plot(column)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:11:07.598276Z","iopub.execute_input":"2022-11-13T22:11:07.603553Z","iopub.status.idle":"2022-11-13T22:11:09.059793Z","shell.execute_reply.started":"2022-11-13T22:11:07.603463Z","shell.execute_reply":"2022-11-13T22:11:09.058559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Cleaning\nThis was previously done in the file import... but included for reference","metadata":{}},{"cell_type":"markdown","source":"#### Salary Cleaning - Find min, max, avg, hourly, & yearly","metadata":{}},{"cell_type":"code","source":"# Separate 'salary' column into that for min max avg and rate (e.g., hourly)\njobs_all[['salary_pay', 'salary_rate']] = jobs_all.salary.str.split(' ', 1, expand=True)\njobs_all.salary_pay = jobs_all.salary_pay.str.replace(',', '').str.replace('$', '').str.replace(' ', '')\njobs_all['salary_avg'] = np.where(jobs_all.salary_pay.str.contains(\"‚Äì\"), np.NaN, jobs_all.salary_pay)  # The character U+2013 \"‚Äì\" could be confused with the character U+002d \"-\", which is more common in source code. Adjust settings\njobs_all['salary_min'] = np.where(jobs_all.salary_pay.str.contains(\"‚Äì\"), jobs_all.salary_pay, np.NaN)\njobs_all[['salary_min', 'salary_max']] = jobs_all.salary_min.str.split(\"‚Äì\", 1, expand=True)\nfor column in ['salary_avg', 'salary_min', 'salary_max']:\n    jobs_all[column] = np.where(jobs_all[column].str.contains(\"K\"), jobs_all[column].str.replace(\"K\", \"\").astype(float) * 1000 , jobs_all[column] )\njobs_all['salary_avg'] = np.where(~jobs_all.salary_min.isnull(), (jobs_all.salary_min.astype(float) + jobs_all.salary_max.astype(float))/2 , jobs_all.salary_avg)\njobs_all['salary_hourly'] = np.where(jobs_all.salary_rate == 'an hour', jobs_all.salary_avg.astype(float), np.NaN)\njobs_all['salary_yearly'] = np.where(jobs_all.salary_rate == 'a year', jobs_all.salary_avg.astype(float), np.NaN)\n\n# Standardize salary to all be annual\njobs_all['salary_standardized'] = np.NaN\nsalary_rate = {'a year': 1, 'an hour': 2080, 'a month': 12}\nfor key, index in salary_rate.items():\n    jobs_all.salary_standardized = np.where(jobs_all.salary_rate == key, jobs_all.salary_avg.astype(float) * index, jobs_all.salary_standardized)\n\n# Used to check results as built above\nsalary_df = jobs_all[~jobs_all.salary.isnull()]\nsalary_df = salary_df[['company_name', 'salary', 'salary_pay', 'salary_rate', 'salary_avg', 'salary_min', 'salary_max', 'salary_standardized', 'salary_hourly', 'salary_yearly']] #, 'salary_min', 'salary_max']\npd.set_option('display.max_rows', salary_df.shape[0]+1)\nsalary_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:11:09.061473Z","iopub.execute_input":"2022-11-13T22:11:09.061868Z","iopub.status.idle":"2022-11-13T22:11:09.137019Z","shell.execute_reply.started":"2022-11-13T22:11:09.061833Z","shell.execute_reply":"2022-11-13T22:11:09.135787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.figure(figsize=(10, 2))\nfig, axs = plt.subplots(3)\nfig.set_figheight(11)\naxs[0].hist(jobs_all.salary_standardized, bins = 20, color = 'plum')\naxs[0].set_title(\"Average Data Analyst Pay\")\naxs[0].set_xlabel(\"($USD/yr) All Salary Standardized to Yearly\")\naxs[1].hist(jobs_all.salary_yearly, bins = 20, color = 'skyblue')\naxs[1].set_xlabel(\"($USD/yr) Annual Salary\")\naxs[2].hist(jobs_all.salary_hourly, bins = 20, color = 'salmon')\naxs[2].set_xlabel(\"($USD/hr) Hourly Pay\")","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:11:09.138838Z","iopub.execute_input":"2022-11-13T22:11:09.139375Z","iopub.status.idle":"2022-11-13T22:11:09.778715Z","shell.execute_reply.started":"2022-11-13T22:11:09.13932Z","shell.execute_reply":"2022-11-13T22:11:09.777426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Description Cleaning - Tokenize Languages & Tools","metadata":{}},{"cell_type":"code","source":"# Picked out keywords based on all keywords (only looked words with 100+ occurrences)\nkeywords_programming = [\n'sql', 'python', 'r', 'c', 'c#', 'javascript', 'js',  'java', 'scala', 'sas', 'matlab', \n'c++', 'c/c++', 'perl', 'go', 'typescript', 'bash', 'html', 'css', 'php', 'powershell', 'rust', \n'kotlin', 'ruby',  'dart', 'assembly', 'swift', 'vba', 'lua', 'groovy', 'delphi', 'objective-c', \n'haskell', 'elixir', 'julia', 'clojure', 'solidity', 'lisp', 'f#', 'fortran', 'erlang', 'apl', \n'cobol', 'ocaml', 'crystal', 'javascript/typescript', 'golang', 'nosql', 'mongodb', 't-sql', 'no-sql',\n'visual_basic', 'pascal', 'mongo', 'pl/sql',  'sass', 'vb.net', 'mssql', \n]\n\nkeywords_libraries = [\n'scikit-learn', 'jupyter', 'theano', 'openCV', 'spark', 'nltk', 'mlpack', 'chainer', 'fann', 'shogun', \n'dlib', 'mxnet', 'node.js', 'vue', 'vue.js', 'keras', 'ember.js', 'jse/jee',\n]\n\nkeywords_analyst_tools = [\n'excel', 'tableau',  'word', 'powerpoint', 'looker', 'powerbi', 'outlook', 'azure', 'jira', 'twilio',  'snowflake', \n'shell', 'linux', 'sas', 'sharepoint', 'mysql', 'visio', 'git', 'mssql', 'powerpoints', 'postgresql', 'spreadsheets',\n'seaborn', 'pandas', 'gdpr', 'spreadsheet', 'alteryx', 'github', 'postgres', 'ssis', 'numpy', 'power_bi', 'spss', 'ssrs', \n'microstrategy',  'cognos', 'dax', 'matplotlib', 'dplyr', 'tidyr', 'ggplot2', 'plotly', 'esquisse', 'rshiny', 'mlr',\n'docker', 'linux', 'jira',  'hadoop', 'airflow', 'redis', 'graphql', 'sap', 'tensorflow', 'node', 'asp.net', 'unix',\n'jquery', 'pyspark', 'pytorch', 'gitlab', 'selenium', 'splunk', 'bitbucket', 'qlik', 'terminal', 'atlassian', 'unix/linux',\n'linux/unix', 'ubuntu', 'nuix', 'datarobot',\n]\n\nkeywords_cloud_tools = [\n'aws', 'azure', 'gcp', 'snowflake', 'redshift', 'bigquery', 'aurora',\n]\n\n# Not using\nkeywords_general_tools = [\n'microsoft', 'slack', 'apache', 'ibm', 'html5', 'datadog', 'bloomberg',  'ajax', 'persicope', 'oracle', \n]\n\n# Not using\nkeywords_general = [\n'coding', 'server', 'database', 'cloud', 'warehousing', 'scrum', 'devops', 'programming', 'saas', 'ci/cd', 'cicd', \n'ml', 'data_lake', 'frontend',' front-end', 'back-end', 'backend', 'json', 'xml', 'ios', 'kanban', 'nlp',\n'iot', 'codebase', 'agile/scrum', 'agile', 'ai/ml', 'ai', 'paas', 'machine_learning', 'macros', 'iaas',\n'fullstack', 'dataops', 'scrum/agile', 'ssas', 'mlops', 'debug', 'etl', 'a/b', 'slack', 'erp', 'oop', \n'object-oriented', 'etl/elt', 'elt', 'dashboarding', 'big-data', 'twilio', 'ui/ux', 'ux/ui', 'vlookup', \n'crossover',  'data_lake', 'data_lakes', 'bi', \n]\n\nkeywords = keywords_programming + keywords_libraries + keywords_analyst_tools + keywords_cloud_tools \n\njobs_all = jobs_all[jobs_all.description.notnull()] # filter out null values\njobs_all = jobs_all.reset_index() # throwing index issues if don't reset index\n# jobs_all = jobs_all.head(10) \n\njobs_all['description_tokens'] = \"\"\nfor index, row in jobs_all.iterrows():\n    # lowercase words\n    detail = row.description.lower()\n    # tokenize words\n    detail = word_tokenize(detail)\n    # handle multi-word tokenization (e.g., 'Power BI')\n    multi_tokens = [('power', 'bi'), ('data', 'lake'), ('data', 'lakes'), ('machine', 'learning'), ('objective', 'c'),\n                    ('visual', 'basic')]\n    tokenizer = MWETokenizer(multi_tokens)\n    detail = tokenizer.tokenize(detail)\n    # remove duplicates\n    detail = list(set(detail))\n    # filter for keywords only\n    detail = [word for word in detail if word in keywords] \n    # replace duplicate keywords\n    replace_tokens = {'powerbi' : 'power_bi', 'spreadsheets': 'spreadsheet'}\n    for key, value in replace_tokens.items():\n        detail = [d.replace(key, value) for d in detail]\n    # add to details list # row.description_tokens = detail\n    jobs_all.at[index, 'description_tokens'] = detail","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:11:09.781047Z","iopub.execute_input":"2022-11-13T22:11:09.78162Z","iopub.status.idle":"2022-11-13T22:11:16.235932Z","shell.execute_reply.started":"2022-11-13T22:11:09.781567Z","shell.execute_reply":"2022-11-13T22:11:16.234993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## More EDA of Top Skills","metadata":{}},{"cell_type":"code","source":"def filtered_keywords(jobs_filtered, keywords, title=\"Keyword Analysis\", head=10):\n    # get keywords in a column\n    count_keywords = pd.DataFrame(jobs_filtered.description_tokens.sum()).value_counts().rename_axis('keywords').reset_index(name='counts')\n\n    # get frequency of occurence of word (as word only appears once per line)\n    length = len(jobs_filtered) # number of job postings\n    count_keywords['percentage'] = 100 * count_keywords.counts / length\n\n    # plot the results\n    count_keywords = count_keywords[count_keywords.keywords.isin(keywords)]\n    count_keywords = count_keywords.head(head)\n    g = plt.bar(x=\"keywords\", height=\"percentage\", data=count_keywords , color=np.random.rand(len(count_keywords.keywords), 3))\n    plt.xlabel(\"\")\n    plt.ylabel(\"Likelyhood to be in job posting (%)\")\n    plt.xticks(rotation = 45, ha='right')\n    plt.title(title) \n    plt.show(g)\n    print(count_keywords)","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:11:16.237311Z","iopub.execute_input":"2022-11-13T22:11:16.237703Z","iopub.status.idle":"2022-11-13T22:11:16.24651Z","shell.execute_reply.started":"2022-11-13T22:11:16.237667Z","shell.execute_reply":"2022-11-13T22:11:16.245126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_keywords(jobs_all, keywords_programming, title=\"Top Programming Languages for Data Analysts\")","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:11:16.24825Z","iopub.execute_input":"2022-11-13T22:11:16.248746Z","iopub.status.idle":"2022-11-13T22:11:16.593844Z","shell.execute_reply.started":"2022-11-13T22:11:16.248698Z","shell.execute_reply":"2022-11-13T22:11:16.592545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_keywords(jobs_all, keywords, title=\"Top Tools for Data Analysts\")","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:11:16.597667Z","iopub.execute_input":"2022-11-13T22:11:16.598446Z","iopub.status.idle":"2022-11-13T22:11:16.793017Z","shell.execute_reply.started":"2022-11-13T22:11:16.598396Z","shell.execute_reply":"2022-11-13T22:11:16.791746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Bonus: Skill vs. Salary","metadata":{}},{"cell_type":"code","source":"# Felt cute... may try to analyze later","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:11:16.794432Z","iopub.execute_input":"2022-11-13T22:11:16.794788Z","iopub.status.idle":"2022-11-13T22:11:16.800224Z","shell.execute_reply.started":"2022-11-13T22:11:16.794757Z","shell.execute_reply":"2022-11-13T22:11:16.798903Z"},"trusted":true},"execution_count":null,"outputs":[]}]}